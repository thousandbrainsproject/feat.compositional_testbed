{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557bc1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tbp.monty.frameworks.utils.logging_utils import load_stats\n",
    "import matplotlib.pyplot as plt\n",
    "from tbp.monty.frameworks.utils.plot_utils import plot_graph\n",
    "import colorsys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23276d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e9768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_path = os.path.expanduser(\"~/tbp/results/monty/pretrained_models/\")\n",
    "pretrained_dict = pretrain_path + \"pretrained_ycb_v10/supervised_pre_training_curved_objects_after_flat_and_logo/pretrained/\"\n",
    "\n",
    "log_path = os.path.expanduser(\"~/tbp/results/monty/projects/evidence_eval_runs/logs/\")\n",
    "exp_name = \"base_config_10distinctobj_dist_agent\"\n",
    "exp_path = log_path + exp_name\n",
    "\n",
    "train_stats, eval_stats, detailed_stats, lm_models_base_objects = load_stats(exp_path,\n",
    "                                                                load_train=False, # doesn't load train csv\n",
    "                                                                load_eval=False, # loads eval_stats.csv\n",
    "                                                                load_detailed=False, # doesn't load .json\n",
    "                                                                load_models=True, # loads .pt models\n",
    "                                                                pretrained_dict=pretrained_dict,\n",
    "                                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b59db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_models_base_objects['pretrained'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95517886",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_models_base_objects['pretrained'][0]['021_logo_tbp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eb67d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(lm_models_base_objects['pretrained'][0]['023_mug']['patch_0'], rotation=120)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e46ad4",
   "metadata": {},
   "source": [
    "\n",
    "## Comparing Lower and Higher Level LM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3d7a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lllm_hllm_models(lm_models, object_id, show_ax_ticks=False, elev=-80, azim=180, roll=180):\n",
    "    lllm_model = lm_models['pretrained'][0][object_id]['patch_0']\n",
    "    hllm_model = lm_models['pretrained'][1][object_id]['patch_1']\n",
    "\n",
    "    lllm_color_idxs = lllm_model.feature_mapping['hsv']\n",
    "    lllm_colors = lllm_model.x[:, lllm_color_idxs[0]:lllm_color_idxs[1]]\n",
    "    hllm_color_idxs = hllm_model.feature_mapping['hsv']\n",
    "    hllm_colors = hllm_model.x[:, hllm_color_idxs[0]:hllm_color_idxs[1]]\n",
    "\n",
    "    # Conver HSV values to RGB\n",
    "    lllm_rgb_colors = [colorsys.hsv_to_rgb(*hsv) for hsv in lllm_colors]\n",
    "    hllm_rgb_colors = [colorsys.hsv_to_rgb(*hsv) for hsv in hllm_colors]\n",
    "\n",
    "    plt.figure()\n",
    "    ax1 = plt.subplot(1, 2, 1, projection='3d')\n",
    "    ax1.scatter(lllm_model.pos[:, 1], lllm_model.pos[:, 0], lllm_model.pos[:, 2], c=lllm_rgb_colors)\n",
    "    ax1.set_aspect(\"equal\")\n",
    "    ax1.set_title(f\"LLLM model of \\n{object_id}\")\n",
    "    ax1.view_init(elev, azim, roll)\n",
    "    if not show_ax_ticks:\n",
    "        ax1.set_xticks([])\n",
    "        ax1.set_yticks([])\n",
    "        ax1.set_zticks([])\n",
    "    ax2 = plt.subplot(1, 2, 2, projection='3d')\n",
    "    ax2.scatter(hllm_model.pos[:, 1], hllm_model.pos[:, 0], hllm_model.pos[:, 2], c=hllm_rgb_colors)\n",
    "    ax2.set_aspect(\"equal\")\n",
    "    ax2.set_title(f\"HLLM model of \\n{object_id}\")\n",
    "    ax2.view_init(elev, azim, roll)\n",
    "    if not show_ax_ticks:\n",
    "        ax2.set_xticks([])\n",
    "        ax2.set_yticks([])\n",
    "        ax2.set_zticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33fcb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lllm_hllm_models(lm_models_base_objects, '001_cube', elev=-50, azim=150, roll=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3bb2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lllm_hllm_models(lm_models_base_objects, '021_logo_tbp', elev=-80, azim=180, roll=180)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f010c458",
   "metadata": {},
   "source": [
    "### Compositional Models Learned with Single Level of Hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8897cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model that has trained on the compositional objects, but with no hierarchical passing of model IDs\n",
    "pretrained_dict = pretrain_path + \"pretrained_ycb_v10/supervised_pre_training_objects_with_logos_lvl1_monolithic_models/pretrained/\"\n",
    "\n",
    "log_path = os.path.expanduser(\"~/tbp/results/monty/projects/evidence_eval_runs/logs/\")\n",
    "exp_name = \"base_config_10distinctobj_dist_agent\"\n",
    "exp_path = log_path + exp_name\n",
    "\n",
    "__, __, __, lm_models_monolithic = load_stats(exp_path,\n",
    "                                                                load_train=False, # doesn't load train csv\n",
    "                                                                load_eval=False, # loads eval_stats.csv\n",
    "                                                                load_detailed=False, # doesn't load .json\n",
    "                                                                load_models=True, # loads .pt models\n",
    "                                                                pretrained_dict=pretrained_dict,\n",
    "                                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb19444",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lllm_hllm_models(lm_models_monolithic, '009_disk_numenta_horz', elev=-50, azim=150, roll=180)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da5b858",
   "metadata": {},
   "source": [
    "## Partially Supervised, Compositional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90fa533",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_path = os.path.expanduser(\"~/tbp/results/monty/pretrained_models/\")\n",
    "pretrained_dict = pretrain_path + \"pretrained_ycb_v10_simplified/supervised_pre_training_objects_with_logos_lvl1_comp_models_resampling/pretrained/\"\n",
    "\n",
    "log_path = os.path.expanduser(\"~/tbp/results/monty/projects/evidence_eval_runs/logs/\")\n",
    "exp_name = \"base_config_10distinctobj_dist_agent\"\n",
    "exp_path = log_path + exp_name\n",
    "\n",
    "train_stats, eval_stats, detailed_stats, lm_models_compositional = load_stats(exp_path,\n",
    "                                                                load_train=False, # doesn't load train csv\n",
    "                                                                load_eval=False, # loads eval_stats.csv\n",
    "                                                                load_detailed=False, # doesn't load .json\n",
    "                                                                load_models=True, # loads .pt models\n",
    "                                                                pretrained_dict=pretrained_dict,\n",
    "                                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cdfaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_models_compositional['pretrained'][1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bad5566",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_models_compositional['pretrained'][1]['002_cube_tbp_horz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7101ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_compositional_models(lm_models, object_id, show_ax_ticks=False, elev=-80, azim=180, roll=180):\n",
    "    patch_1_model = lm_models['pretrained'][1][object_id]['patch_1']\n",
    "    lm0_model = lm_models['pretrained'][1][object_id]['learning_module_0']\n",
    "\n",
    "    hllm_color_idxs = patch_1_model.feature_mapping['hsv']\n",
    "    hllm_colors = patch_1_model.x[:, hllm_color_idxs[0]:hllm_color_idxs[1]]\n",
    "    # Conver HSV values to RGB\n",
    "    hllm_rgb_colors = [colorsys.hsv_to_rgb(*hsv) for hsv in hllm_colors]\n",
    "\n",
    "    hllm_obj_idxs = lm0_model.feature_mapping['object_id']\n",
    "    hllm_obj_ids = lm0_model.x[:, hllm_obj_idxs[0]:hllm_obj_idxs[1]]\n",
    "    print(np.unique(hllm_obj_ids))\n",
    "\n",
    "    plt.figure()\n",
    "    ax1 = plt.subplot(1, 2, 1, projection='3d')\n",
    "    ax1.scatter(patch_1_model.pos[:, 1], patch_1_model.pos[:, 0], patch_1_model.pos[:, 2], c=hllm_rgb_colors)\n",
    "    ax1.set_aspect(\"equal\")\n",
    "    ax1.set_title(f\"HLLM model from SM input of \\n{object_id}\")\n",
    "    ax1.view_init(elev, azim, roll)\n",
    "    if not show_ax_ticks:\n",
    "        ax1.set_xticks([])\n",
    "        ax1.set_yticks([])\n",
    "        ax1.set_zticks([])\n",
    "    ax2 = plt.subplot(1, 2, 2, projection='3d')\n",
    "    ax2.scatter(lm0_model.pos[:, 1], lm0_model.pos[:, 0], lm0_model.pos[:, 2], c=hllm_obj_ids)\n",
    "    ax2.set_aspect(\"equal\")\n",
    "    ax2.set_title(f\"HLLM model from LM input \\n{object_id}\")\n",
    "    ax2.view_init(elev, azim, roll)\n",
    "    if not show_ax_ticks:\n",
    "        ax2.set_xticks([])\n",
    "        ax2.set_yticks([])\n",
    "        ax2.set_zticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215129fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_compositional_models(lm_models_compositional, '004_cube_numenta_horz', elev=-50, azim=150, roll=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c361bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_id_to_features(object_id):\n",
    "    \"\"\"Turn object ID into features that express object similarity.\n",
    "\n",
    "    Returns:\n",
    "        The object ID features.\n",
    "    \"\"\"\n",
    "    # TODO H: Make this based on object similarity\n",
    "    # For now just taking sum of character ids in object name\n",
    "    id_feature = sum(ord(i) for i in object_id)\n",
    "    print(f\"id_feature for {object_id}: {id_feature}\")\n",
    "    return id_feature\n",
    "\n",
    "for key in lm_models_compositional['pretrained'][1].keys():\n",
    "    object_id_to_features(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a8d4bb",
   "metadata": {},
   "source": [
    "### Compare Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514949c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tbp.monty.frameworks.utils.logging_utils import compositional_stats_for_all_lms, mean_num_steps_for_lm\n",
    "from src.tbp.monty.frameworks.environments.logos_on_objs import PARENT_TO_CHILD_MAPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32a1f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_path = os.path.expanduser(\"~/tbp/results/monty/pretrained_models/\")\n",
    "log_path = os.path.expanduser(\"~/tbp/results/monty/projects/evidence_eval_runs/logs/\")\n",
    "\n",
    "pretrained_dict_monolithic = pretrain_path + \"pretrained_ycb_v10/supervised_pre_training_objects_with_logos_lvl1_monolithic_models/pretrained/\"\n",
    "exp_path = log_path + \"infer_comp_lvl1_with_monolithic_models\"\n",
    "_, eval_stats_monolithic, detailed_stats_monolithic, lm_models_monolithic = load_stats(exp_path,\n",
    "                                                                load_train=False, # doesn't load train csv\n",
    "                                                                load_eval=True, # loads eval_stats.csv\n",
    "                                                                load_detailed=True, # doesn't load .json\n",
    "                                                                load_models=True, # loads .pt models\n",
    "                                                                pretrained_dict=pretrained_dict_monolithic,\n",
    "                                                               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a9633c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_dict_compositional = pretrain_path + \"pretrained_ycb_v10/supervised_pre_training_objects_with_logos_lvl1_comp_models/pretrained/\"\n",
    "exp_path = log_path + \"infer_comp_lvl1_with_comp_models\"\n",
    "_, eval_stats, detailed_stats_compositional, lm_models_compositional = load_stats(exp_path,\n",
    "                                                                load_train=False, # doesn't load train csv\n",
    "                                                                load_eval=True, # loads eval_stats.csv\n",
    "                                                                load_detailed=True, # doesn't load .json\n",
    "                                                                load_models=True, # loads .pt models\n",
    "                                                                pretrained_dict=pretrained_dict_compositional,\n",
    "                                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e458bcf606e04c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_prediction_errors(detailed_stats, lm_id):\n",
    "    raw_prediction_error = detailed_stats['0'][lm_id]['mlh_prediction_error']\n",
    "    processed_steps = detailed_stats['0'][lm_id]['lm_processed_steps']\n",
    "\n",
    "    prediction_error = []\n",
    "    prediction_error_index = 0\n",
    "    for step in processed_steps:\n",
    "        if step and prediction_error_index < len(raw_prediction_error):\n",
    "            prediction_error.append(raw_prediction_error[prediction_error_index])\n",
    "            prediction_error_index += 1\n",
    "        else:\n",
    "            prediction_error.append(None)\n",
    "    return np.array(prediction_error)\n",
    "\n",
    "def filter_prediction_errors(lm1_prediction_error, lm2_prediction_error):\n",
    "    lm1_has_values = lm1_prediction_error != None\n",
    "    lm2_has_values = lm2_prediction_error != None\n",
    "    either_have_values = np.logical_or(lm1_has_values, lm2_has_values)\n",
    "\n",
    "    lm1_prediction_error = lm1_prediction_error[either_have_values]\n",
    "    lm2_prediction_error = lm2_prediction_error[either_have_values]\n",
    "    return lm1_prediction_error, lm2_prediction_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbc8720500647bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm1_prediction_error = align_prediction_errors(detailed_stats_monolithic, \"LM_0\")\n",
    "lm2_prediction_error = align_prediction_errors(detailed_stats_monolithic, \"LM_1\")\n",
    "\n",
    "lm1_prediction_error, lm2_prediction_error = filter_prediction_errors(lm1_prediction_error, lm2_prediction_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708fa7a2d6edb6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(lm1_prediction_error, color='lightgrey')\n",
    "plt.plot(lm2_prediction_error, color='grey')\n",
    "plt.legend(['LM_0', 'LM_1'])\n",
    "plt.title(\"Prediction Error\")\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3baf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm1_prediction_error_comp = align_prediction_errors(detailed_stats_compositional, \"LM_0\")\n",
    "lm2_prediction_error_comp = align_prediction_errors(detailed_stats_compositional, \"LM_1\")\n",
    "\n",
    "lm1_prediction_error_comp, lm2_prediction_error_comp = filter_prediction_errors(lm1_prediction_error_comp, lm2_prediction_error_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e496ec7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(lm1_prediction_error_comp, color='lightgreen')\n",
    "plt.plot(lm2_prediction_error_comp, color='green')\n",
    "plt.legend(['LM_0', 'LM_1'])\n",
    "plt.title(\"Prediction Error\")\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e9f83006aefa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_stats_monolithic.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ef76cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Stats for Monolithic Models:\")\n",
    "monolithic_accuracy_dict = compositional_stats_for_all_lms(eval_stats_monolithic, [0, 1], PARENT_TO_CHILD_MAPPING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7b7bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Stats for Compositional Models:\")\n",
    "compositional_accuracy_dict = compositional_stats_for_all_lms(eval_stats, [0, 1], PARENT_TO_CHILD_MAPPING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462bc4a9dfff0cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_steps_mono = mean_num_steps_for_lm(eval_stats_monolithic, \"LM_1\")\n",
    "mean_steps_comp = mean_num_steps_for_lm(eval_stats, \"LM_1\")\n",
    "\n",
    "accuracy_monolithic_lm0 = monolithic_accuracy_dict[0][\"compositional_object_accuracy\"]\n",
    "accuracy_compositional_lm0 = compositional_accuracy_dict[0][\"compositional_object_accuracy\"]\n",
    "\n",
    "consistent_child_monolithic_lm0 = monolithic_accuracy_dict[0][\"consistent_child_accuracy\"]\n",
    "consistent_child_compositional_lm0 = compositional_accuracy_dict[0][\"consistent_child_accuracy\"]\n",
    "\n",
    "accuracy_monolithic_lm1 = monolithic_accuracy_dict[1][\"compositional_object_accuracy\"]\n",
    "accuracy_compositional_lm1 = compositional_accuracy_dict[1][\"compositional_object_accuracy\"]\n",
    "\n",
    "consistent_child_monolithic_lm1 = monolithic_accuracy_dict[1][\"consistent_child_accuracy\"]\n",
    "consistent_child_compositional_lm1 = compositional_accuracy_dict[1][\"consistent_child_accuracy\"]\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.subplot(2,2, 1)\n",
    "plt.bar([0, 1], [accuracy_monolithic_lm0 + consistent_child_monolithic_lm0, accuracy_compositional_lm0 + consistent_child_compositional_lm0], color=[\"lightgrey\", \"lightblue\"])\n",
    "plt.bar([0, 1], [accuracy_monolithic_lm0, accuracy_compositional_lm0], color=[\"grey\", \"blue\"])\n",
    "plt.xticks([0, 1], [\"Monolithic\", \"Compositional\"])\n",
    "plt.ylabel(\"% Correct - LLLM\")\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.subplot(2,2,2)\n",
    "plt.bar([0, 1], [accuracy_monolithic_lm1 + consistent_child_monolithic_lm1, accuracy_compositional_lm1 + consistent_child_compositional_lm1], color=[\"lightgrey\", \"lightgreen\"])\n",
    "plt.bar([0, 1], [accuracy_monolithic_lm1, accuracy_compositional_lm1], color=[\"darkgrey\", \"green\"])\n",
    "plt.xticks([0, 1], [\"Monolithic\", \"Compositional\"])\n",
    "plt.ylabel(\"% Correct - HLLM\")\n",
    "plt.legend([\"Consistent Child\", \"Correct\"], loc=\"upper left\")\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.subplot(2,2, 3)\n",
    "plt.bar([0, 1], [mean_steps_mono, mean_steps_comp], color=[\"grey\", \"blue\"])\n",
    "plt.xticks([0, 1], [\"Monolithic\", \"Compositional\"])\n",
    "plt.ylabel(\"Mean Number of Steps\")\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.subplot(2,2, 4)\n",
    "plt.bar([0, 1, 2, 3], [monolithic_accuracy_dict[0][\"episode_avg_prediction_error\"], monolithic_accuracy_dict[1][\"episode_avg_prediction_error\"], compositional_accuracy_dict[0][\"episode_avg_prediction_error\"], compositional_accuracy_dict[1][\"episode_avg_prediction_error\"]], color=[\"grey\", \"blue\", \"darkgrey\", \"green\"])\n",
    "plt.xticks([0, 1, 2, 3], [\"Monolithic - LLLM\", \"Monolithic - HLLM\", \"Compositional - LLLM\", \"Compositional - HLLM\"], rotation=45)\n",
    "plt.ylabel(\"Average Prediction Error\")\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3be8816",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feat.compositional_testbed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
