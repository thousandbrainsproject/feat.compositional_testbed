{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557bc1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tbp.monty.frameworks.utils.logging_utils import load_stats\n",
    "import matplotlib.pyplot as plt\n",
    "from tbp.monty.frameworks.utils.plot_utils import plot_graph\n",
    "import colorsys\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23276d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e9768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_path = os.path.expanduser(\"~/tbp/results/monty/pretrained_models/\")\n",
    "pretrained_dict = pretrain_path + \"pretrained_ycb_v10/supervised_pre_training_objects_wo_logos/pretrained/\"\n",
    "\n",
    "log_path = os.path.expanduser(\"~/tbp/results/monty/projects/evidence_eval_runs/logs/\")\n",
    "exp_name = \"base_config_10distinctobj_dist_agent\"\n",
    "exp_path = log_path + exp_name\n",
    "\n",
    "train_stats, eval_stats, detailed_stats, lm_models_base_objects = load_stats(exp_path,\n",
    "                                                                load_train=False, # doesn't load train csv\n",
    "                                                                load_eval=False, # loads eval_stats.csv\n",
    "                                                                load_detailed=False, # doesn't load .json\n",
    "                                                                load_models=True, # loads .pt models\n",
    "                                                                pretrained_dict=pretrained_dict,\n",
    "                                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b59db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_models['pretrained'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95517886",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_models['pretrained'][0]['021_logo_tbp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eb67d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(lm_models['pretrained'][0]['022_logo_numenta']['patch_0'], rotation=120)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e46ad4",
   "metadata": {},
   "source": [
    "\n",
    "## Comparing Lower and Higher Level LM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3d7a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lllm_hllm_models(lm_models, object_id, show_ax_ticks=False, elev=-80, azim=180, roll=180):\n",
    "    lllm_model = lm_models['pretrained'][0][object_id]['patch_0']\n",
    "    hllm_model = lm_models['pretrained'][1][object_id]['patch_1']\n",
    "\n",
    "    lllm_color_idxs = lllm_model.feature_mapping['hsv']\n",
    "    lllm_colors = lllm_model.x[:, lllm_color_idxs[0]:lllm_color_idxs[1]]\n",
    "    hllm_color_idxs = hllm_model.feature_mapping['hsv']\n",
    "    hllm_colors = hllm_model.x[:, hllm_color_idxs[0]:hllm_color_idxs[1]]\n",
    "\n",
    "    # Conver HSV values to RGB\n",
    "    lllm_rgb_colors = [colorsys.hsv_to_rgb(*hsv) for hsv in lllm_colors]\n",
    "    hllm_rgb_colors = [colorsys.hsv_to_rgb(*hsv) for hsv in hllm_colors]\n",
    "\n",
    "    plt.figure()\n",
    "    ax1 = plt.subplot(1, 2, 1, projection='3d')\n",
    "    ax1.scatter(lllm_model.pos[:, 1], lllm_model.pos[:, 0], lllm_model.pos[:, 2], c=lllm_rgb_colors)\n",
    "    ax1.set_aspect(\"equal\")\n",
    "    ax1.set_title(f\"LLLM model of \\n{object_id}\")\n",
    "    ax1.view_init(elev, azim, roll)\n",
    "    if not show_ax_ticks:\n",
    "        ax1.set_xticks([])\n",
    "        ax1.set_yticks([])\n",
    "        ax1.set_zticks([])\n",
    "    ax2 = plt.subplot(1, 2, 2, projection='3d')\n",
    "    ax2.scatter(hllm_model.pos[:, 1], hllm_model.pos[:, 0], hllm_model.pos[:, 2], c=hllm_rgb_colors)\n",
    "    ax2.set_aspect(\"equal\")\n",
    "    ax2.set_title(f\"HLLM model of \\n{object_id}\")\n",
    "    ax2.view_init(elev, azim, roll)\n",
    "    if not show_ax_ticks:\n",
    "        ax2.set_xticks([])\n",
    "        ax2.set_yticks([])\n",
    "        ax2.set_zticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1603b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_models['pretrained'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ce1346",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lllm_hllm_models(avg_hsv_models, '001_cube', elev=-50, azim=150, roll=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33fcb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lllm_hllm_models(lm_models_base_objects, '001_cube', elev=-50, azim=150, roll=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3bb2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lllm_hllm_models(lm_models_base_objects, '021_logo_tbp', elev=-80, azim=180, roll=180)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f010c458",
   "metadata": {},
   "source": [
    "### Compositional Models Learned with Single Level of Hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28233059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBJECT_WITH_LOGOS = [\n",
    "#     \"002_cube_tbp_horz\",\n",
    "#     \"004_cube_numenta_horz\",\n",
    "#     \"007_disk_tbp_horz\",\n",
    "#     \"009_disk_numenta_horz\",\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8897cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model that has trained on the compositional objects, but with no hierarchical passing of model IDs\n",
    "pretrained_dict = pretrain_path + \"pretrained_ycb_v10/supervised_pre_training_compositional_objects_with_logos/pretrained/\"\n",
    "\n",
    "log_path = os.path.expanduser(\"~/tbp/results/monty/projects/evidence_eval_runs/logs/\")\n",
    "exp_name = \"base_config_10distinctobj_dist_agent\"\n",
    "exp_path = log_path + exp_name\n",
    "\n",
    "__, __, __, lm_models_single_level = load_stats(exp_path,\n",
    "                                                                load_train=False, # doesn't load train csv\n",
    "                                                                load_eval=False, # loads eval_stats.csv\n",
    "                                                                load_detailed=False, # doesn't load .json\n",
    "                                                                load_models=True, # loads .pt models\n",
    "                                                                pretrained_dict=pretrained_dict,\n",
    "                                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb19444",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lllm_hllm_models(lm_models_single_level, '009_disk_numenta_horz', elev=-50, azim=150, roll=180)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07236090",
   "metadata": {},
   "source": [
    "#### Smaller Step Size (1 rather than 5 degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd548f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model that has trained on the compositional objects, but with no hierarchical passing of model IDs\n",
    "pretrained_dict = pretrain_path + \"pretrained_ycb_v10/supervised_pre_training_compositional_objects_with_logos_small_step_size/pretrained/\"\n",
    "\n",
    "log_path = os.path.expanduser(\"~/tbp/results/monty/projects/evidence_eval_runs/logs/\")\n",
    "exp_name = \"base_config_10distinctobj_dist_agent\"\n",
    "exp_path = log_path + exp_name\n",
    "\n",
    "__, __, __, lm_models_single_level_small_step_size = load_stats(exp_path,\n",
    "                                                                load_train=False, # doesn't load train csv\n",
    "                                                                load_eval=False, # loads eval_stats.csv\n",
    "                                                                load_detailed=False, # doesn't load .json\n",
    "                                                                load_models=True, # loads .pt models\n",
    "                                                                pretrained_dict=pretrained_dict,\n",
    "                                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71587ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lllm_hllm_models(lm_models_single_level_small_step_size, '009_disk_numenta_horz', elev=-50, azim=150, roll=180)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da5b858",
   "metadata": {},
   "source": [
    "## Partially Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90fa533",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_path = os.path.expanduser(\"~/tbp/results/monty/pretrained_models/\")\n",
    "pretrained_dict = pretrain_path + \"pretrained_ycb_v10/partial_supervised_pre_training_comp_objects/pretrained/\"\n",
    "\n",
    "log_path = os.path.expanduser(\"~/tbp/results/monty/projects/evidence_eval_runs/logs/\")\n",
    "exp_name = \"base_config_10distinctobj_dist_agent\"\n",
    "exp_path = log_path + exp_name\n",
    "\n",
    "train_stats, eval_stats, detailed_stats, lm_models_compositional = load_stats(exp_path,\n",
    "                                                                load_train=False, # doesn't load train csv\n",
    "                                                                load_eval=False, # loads eval_stats.csv\n",
    "                                                                load_detailed=False, # doesn't load .json\n",
    "                                                                load_models=True, # loads .pt models\n",
    "                                                                pretrained_dict=pretrained_dict,\n",
    "                                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cdfaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_models_compositional['pretrained'][1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bad5566",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_models_compositional['pretrained'][1]['004_cube_numenta_horz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7101ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_compositional_models(lm_models, object_id, show_ax_ticks=False, elev=-80, azim=180, roll=180):\n",
    "    patch_1_model = lm_models['pretrained'][1][object_id]['patch_1']\n",
    "    lm0_model = lm_models['pretrained'][1][object_id]['learning_module_0']\n",
    "\n",
    "    hllm_color_idxs = patch_1_model.feature_mapping['hsv']\n",
    "    hllm_colors = patch_1_model.x[:, hllm_color_idxs[0]:hllm_color_idxs[1]]\n",
    "    # Conver HSV values to RGB\n",
    "    hllm_rgb_colors = [colorsys.hsv_to_rgb(*hsv) for hsv in hllm_colors]\n",
    "\n",
    "    hllm_obj_idxs = lm0_model.feature_mapping['object_id']\n",
    "    hllm_obj_ids = lm0_model.x[:, hllm_obj_idxs[0]:hllm_obj_idxs[1]]\n",
    "    print(np.unique(hllm_obj_ids))\n",
    "\n",
    "    plt.figure()\n",
    "    ax1 = plt.subplot(1, 2, 1, projection='3d')\n",
    "    ax1.scatter(patch_1_model.pos[:, 1], patch_1_model.pos[:, 0], patch_1_model.pos[:, 2], c=hllm_rgb_colors)\n",
    "    ax1.set_aspect(\"equal\")\n",
    "    ax1.set_title(f\"HLLM model from SM input of \\n{object_id}\")\n",
    "    ax1.view_init(elev, azim, roll)\n",
    "    if not show_ax_ticks:\n",
    "        ax1.set_xticks([])\n",
    "        ax1.set_yticks([])\n",
    "        ax1.set_zticks([])\n",
    "    ax2 = plt.subplot(1, 2, 2, projection='3d')\n",
    "    ax2.scatter(lm0_model.pos[:, 1], lm0_model.pos[:, 0], lm0_model.pos[:, 2], c=hllm_obj_ids)\n",
    "    ax2.set_aspect(\"equal\")\n",
    "    ax2.set_title(f\"HLLM model from LM input \\n{object_id}\")\n",
    "    ax2.view_init(elev, azim, roll)\n",
    "    if not show_ax_ticks:\n",
    "        ax2.set_xticks([])\n",
    "        ax2.set_yticks([])\n",
    "        ax2.set_zticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215129fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_compositional_models(lm_models_compositional, '007_disk_tbp_horz', elev=-50, azim=150, roll=180)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a8d4bb",
   "metadata": {},
   "source": [
    "### Compare Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514949c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tbp.monty.frameworks.utils.logging_utils import print_overall_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32a1f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_path = log_path + \"base_config_cube_disk_logos_dist_agent\"\n",
    "_, eval_stats_base, _, lm_models_compositional = load_stats(exp_path,\n",
    "                                                                load_train=False, # doesn't load train csv\n",
    "                                                                load_eval=True, # loads eval_stats.csv\n",
    "                                                                load_detailed=False, # doesn't load .json\n",
    "                                                                load_models=True, # loads .pt models\n",
    "                                                                pretrained_dict=pretrained_dict,\n",
    "                                                               )\n",
    "exp_path = log_path + \"cube_disk_logos_with_pretrained_models\"\n",
    "_, eval_stats_comp, _, _ = load_stats(exp_path,\n",
    "                                                                load_train=False, # doesn't load train csv\n",
    "                                                                load_eval=True, # loads eval_stats.csv\n",
    "                                                                load_detailed=False, # doesn't load .json\n",
    "                                                                load_models=False, # loads .pt models\n",
    "                                                                pretrained_dict=pretrained_dict,\n",
    "                                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6574bc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_stats_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0340e767",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_overall_stats(eval_stats_comp[eval_stats_comp[\"lm_id\"]==\"LM_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984c7089",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_stats = eval_stats_comp[eval_stats_comp[\"lm_id\"]==f\"LM_0\"]\n",
    "for c, episode_stats in lm_stats.iterrows():\n",
    "    print(f\"episode stats: {episode_stats.most_likely_object}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8157d962",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_to_child_mapping = {\n",
    "    \"002_cube_tbp_horz\": [\"001_cube\", \"021_logo_tbp\"],\n",
    "    \"004_cube_numenta_horz\": [\"001_cube\", \"022_logo_numenta\"],\n",
    "    \"007_disk_tbp_horz\": [\"006_disk\", \"021_logo_tbp\"],\n",
    "    \"009_disk_numenta_horz\": [\"006_disk\", \"022_logo_numenta\"],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45237a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_compositional_object_accuracy(eval_stats_for_lm):\n",
    "    acc = (\n",
    "        (\n",
    "            len(lm_stats[lm_stats[\"primary_performance\"] == \"correct\"])\n",
    "            + len(lm_stats[lm_stats[\"primary_performance\"] == \"correct_mlh\"])\n",
    "        )\n",
    "        / len(lm_stats)\n",
    "        * 100\n",
    "    )\n",
    "    return acc\n",
    "\n",
    "def calculate_consistent_child_objects_accuracy(eval_stats_for_lm, parent_to_child_mapping):\n",
    "    \"\"\"Check whether the most_likely_object is consistent with the parent_to_child_mapping.\n",
    "    \n",
    "    Classified object is consistent if it is one of the children in the set of objects\n",
    "    corresponding to the compositional object.\n",
    "    \"\"\"\n",
    "    \n",
    "    consistent_child_count = 0\n",
    "    total_count = 0\n",
    "    \n",
    "    for _, episode_stats in eval_stats_for_lm.iterrows():\n",
    "        if episode_stats.primary_target_object in parent_to_child_mapping:\n",
    "            total_count += 1\n",
    "            possible_children = parent_to_child_mapping[episode_stats.primary_target_object]\n",
    "            if episode_stats.most_likely_object in possible_children:\n",
    "                consistent_child_count += 1\n",
    "        else:\n",
    "            print(f\"target object {episode_stats.primary_target_object} not in parent_to_child_mapping\")\n",
    "    if total_count > 0:\n",
    "        consistent_child_percentage = consistent_child_count / total_count\n",
    "        return consistent_child_percentage\n",
    "    else:\n",
    "        raise ValueError(\"No mappings found for target object\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018ad023",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def accuracy_stats_for_compositional_objects(eval_stats_for_lm, parent_to_child_mapping):\n",
    "    compositional_object_accuracy = calculate_compositional_object_accuracy(eval_stats_for_lm)\n",
    "    consistent_child_accuracy = calculate_consistent_child_objects_accuracy(eval_stats_for_lm, parent_to_child_mapping)\n",
    "\n",
    "    return compositional_object_accuracy, consistent_child_accuracy\n",
    "\n",
    "def stats_for_all_lms(eval_stats_comp, all_lm_ids, parent_to_child_mapping):\n",
    "    for lm_id in all_lm_ids:\n",
    "        eval_stats_for_lm = eval_stats_comp[eval_stats_comp[\"lm_id\"]==f\"LM_{lm_id}\"]\n",
    "        compositional_object_accuracy, consistent_child_accuracy = accuracy_stats_for_compositional_objects(eval_stats_for_lm, parent_to_child_mapping)\n",
    "        print(f\"LM_{lm_id} accuracy: {compositional_object_accuracy}\")\n",
    "        print(f\"LM_{lm_id} consistent child accuracy: {consistent_child_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697f397e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_id = 0\n",
    "eval_stats_for_lm = eval_stats_comp[eval_stats_comp[\"lm_id\"]==f\"LM_{lm_id}\"]\n",
    "\n",
    "calculate_consistent_child_objects_accuracy(eval_stats_for_lm, parent_to_child_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f986de8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_compositional_object_accuracy(eval_stats_for_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42112a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_for_all_lms(eval_stats_comp, [0, 1], parent_to_child_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9190b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feat.compositional_testbed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
